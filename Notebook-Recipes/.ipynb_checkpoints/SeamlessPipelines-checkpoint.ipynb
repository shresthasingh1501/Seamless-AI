{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dced713f-3cb1-4bb5-a784-130987fcafa1",
   "metadata": {},
   "source": [
    "## Seamless Pipelines Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72428e3b-5926-40ac-9679-4c07b482cc46",
   "metadata": {},
   "source": [
    "**Importing important libraries**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722dd147-6580-4cbe-9143-14ae66d6f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests pydub pyaudio wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6c0672-0ec4-4f48-b177-9b7185214de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import base64\n",
    "import pyaudio\n",
    "import wave\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54706366-3121-4512-8e8a-5bf09d5dfb18",
   "metadata": {},
   "source": [
    "**Defining ASR TTS AND NMT FUNCTIONS(BHASHINI)(CHECK RESPECTIVE NOTEBOOK FOR MORE DETAILED LOOK)**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c4a62e-3b9b-4a60-9bd3-843d8f55a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asr(base64_input, input_language):\n",
    "    url = \"https://dhruva-api.bhashini.gov.in/services/inference/pipeline\"\n",
    "    asr_serviceid_dict = {'bn': 'ai4bharat/conformer-multilingual-indo_aryan-gpu--t4', 'en': 'ai4bharat/whisper-medium-en--gpu--t4', 'gu': 'ai4bharat/conformer-multilingual-indo_aryan-gpu--t4', 'hi': 'ai4bharat/conformer-hi-gpu--t4', 'kn': 'ai4bharat/conformer-multilingual-dravidian-gpu--t4', 'ml': 'ai4bharat/conformer-multilingual-dravidian-gpu--t4', 'mr': 'ai4bharat/conformer-multilingual-indo_aryan-gpu--t4', 'or': 'ai4bharat/conformer-multilingual-indo_aryan-gpu--t4', 'pa': 'ai4bharat/conformer-multilingual-indo_aryan-gpu--t4', 'sa': 'ai4bharat/conformer-multilingual-indo_aryan-gpu--t4', 'ta': 'ai4bharat/conformer-multilingual-dravidian-gpu--t4', 'te': 'ai4bharat/conformer-multilingual-dravidian-gpu--t4', 'ur': 'ai4bharat/conformer-multilingual-indo_aryan-gpu--t4'}\n",
    "\n",
    "    asr_serviceid_val = asr_serviceid_dict[input_language]\n",
    "\n",
    "    payload = json.dumps({\n",
    "    \"pipelineTasks\": [\n",
    "        {\n",
    "        \"taskType\": \"asr\",\n",
    "        \"config\": {\n",
    "            \"language\": {\n",
    "            \"sourceLanguage\": input_language\n",
    "            },\n",
    "            \"serviceId\": asr_serviceid_val,\n",
    "            \"audioFormat\": \"wav\",\n",
    "            \"samplingRate\": 16000\n",
    "        }\n",
    "        }\n",
    "    ],\n",
    "    \"inputData\": {\n",
    "        \"audio\": [\n",
    "        {\n",
    "            \"audioContent\": base64_input\n",
    "        }\n",
    "        ]\n",
    "    }\n",
    "    })\n",
    "    headers = {\n",
    "    'Accept': '*/*',\n",
    "    'User-Agent': 'Thunder Client (https://www.thunderclient.com)',\n",
    "    'Authorization': bhashini_api_key,\n",
    "    'Content-Type': 'application/json',\n",
    "    \"Connection\": \"keep-alive\"\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    json_data = json.loads(response.text)\n",
    "    output = json_data[\"pipelineResponse\"][0][\"output\"][0][\"source\"]\n",
    "    return(output)\n",
    "def nmt(my_input, input_language, output_language='en'):\n",
    "    url = \"https://dhruva-api.bhashini.gov.in/services/inference/pipeline\"\n",
    "    nmt_serviceid_dict = {'bn,en': 'ai4bharat/indictrans-v2-all-gpu--t4', 'bn,as': 'ai4bharat/indictrans-v2-all-gpu--t4', 'bn,brx': 'ai4bharat/indictrans-v2-all-gpu--t4', 'bn,gu': 'ai4bharat/indictrans-v2-all-gpu--t4', 'bn,hi': 'ai4bharat/indictrans-v2-all-gpu--t4', 'bn,kn': 'ai4bharat/indictrans-v2-all-gpu--t4', 'bn,ml': 'ai4bharat/indictrans-v2-all-gpu--t4', 'bn,mni': 'ai4bharat/indictrans-v2-all-gpu--t4', 'bn,mr': 'ai4bharat/indictrans-v2-all-gpu--t4', 'bn,or': 'ai4bharat/indictrans-v2-all-gpu--t4', 'bn,pa': 'ai4bharat/indictrans-v2-all-gpu--t4', 'bn,ta': 'ai4bharat/indictrans-v2-all-gpu--t4', 'bn,te': 'ai4bharat/indictrans-v2-all-gpu--t4', 'en,as': 'ai4bharat/indictrans-v2-all-gpu--t4', 'en,bn': 'ai4bharat/indictrans-v2-all-gpu--t4', 'en,brx': 'ai4bharat/indictrans-v2-all-gpu--t4', 'en,gu': 'ai4bharat/indictrans-v2-all-gpu--t4', 'en,hi': 'ai4bharat/indictrans-v2-all-gpu--t4', 'en,kn': 'ai4bharat/indictrans-v2-all-gpu--t4', 'en,ml': 'ai4bharat/indictrans-v2-all-gpu--t4', 'en,mni': 'ai4bharat/indictrans-v2-all-gpu--t4', 'en,mr': 'ai4bharat/indictrans-v2-all-gpu--t4', 'en,or': 'ai4bharat/indictrans-v2-all-gpu--t4', 'en,pa': 'ai4bharat/indictrans-v2-all-gpu--t4', 'en,ta': 'ai4bharat/indictrans-v2-all-gpu--t4', 'en,te': 'ai4bharat/indictrans-v2-all-gpu--t4', 'gu,en': 'ai4bharat/indictrans-v2-all-gpu--t4', 'gu,as': 'ai4bharat/indictrans-v2-all-gpu--t4', 'gu,bn': 'ai4bharat/indictrans-v2-all-gpu--t4', 'gu,brx': 'ai4bharat/indictrans-v2-all-gpu--t4', 'gu,hi': 'ai4bharat/indictrans-v2-all-gpu--t4', 'gu,kn': 'ai4bharat/indictrans-v2-all-gpu--t4', 'gu,ml': 'ai4bharat/indictrans-v2-all-gpu--t4', 'gu,mni': 'ai4bharat/indictrans-v2-all-gpu--t4', 'gu,mr': 'ai4bharat/indictrans-v2-all-gpu--t4', 'gu,or': 'ai4bharat/indictrans-v2-all-gpu--t4', 'gu,pa': 'ai4bharat/indictrans-v2-all-gpu--t4', 'gu,ta': 'ai4bharat/indictrans-v2-all-gpu--t4', 'gu,te': 'ai4bharat/indictrans-v2-all-gpu--t4', 'hi,en': 'ai4bharat/indictrans-v2-all-gpu--t4', 'hi,as': 'ai4bharat/indictrans-v2-all-gpu--t4', 'hi,bn': 'ai4bharat/indictrans-v2-all-gpu--t4', 'hi,brx': 'ai4bharat/indictrans-v2-all-gpu--t4', 'hi,gu': 'ai4bharat/indictrans-v2-all-gpu--t4', 'hi,kn': 'ai4bharat/indictrans-v2-all-gpu--t4', 'hi,ml': 'ai4bharat/indictrans-v2-all-gpu--t4', 'hi,mni': 'ai4bharat/indictrans-v2-all-gpu--t4', 'hi,mr': 'ai4bharat/indictrans-v2-all-gpu--t4', 'hi,or': 'ai4bharat/indictrans-v2-all-gpu--t4', 'hi,pa': 'ai4bharat/indictrans-v2-all-gpu--t4', 'hi,ta': 'ai4bharat/indictrans-v2-all-gpu--t4', 'hi,te': 'ai4bharat/indictrans-v2-all-gpu--t4', 'kn,en': 'ai4bharat/indictrans-v2-all-gpu--t4', 'kn,as': 'ai4bharat/indictrans-v2-all-gpu--t4', 'kn,bn': 'ai4bharat/indictrans-v2-all-gpu--t4', 'kn,brx': 'ai4bharat/indictrans-v2-all-gpu--t4', 'kn,gu': 'ai4bharat/indictrans-v2-all-gpu--t4', 'kn,hi': 'ai4bharat/indictrans-v2-all-gpu--t4', 'kn,ml': 'ai4bharat/indictrans-v2-all-gpu--t4', 'kn,mni': 'ai4bharat/indictrans-v2-all-gpu--t4', 'kn,mr': 'ai4bharat/indictrans-v2-all-gpu--t4', 'kn,or': 'ai4bharat/indictrans-v2-all-gpu--t4', 'kn,pa': 'ai4bharat/indictrans-v2-all-gpu--t4', 'kn,ta': 'ai4bharat/indictrans-v2-all-gpu--t4', 'kn,te': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ml,en': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ml,as': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ml,bn': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ml,brx': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ml,gu': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ml,hi': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ml,kn': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ml,mni': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ml,mr': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ml,or': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ml,pa': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ml,ta': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ml,te': 'ai4bharat/indictrans-v2-all-gpu--t4', 'mr,en': 'ai4bharat/indictrans-v2-all-gpu--t4', 'mr,as': 'ai4bharat/indictrans-v2-all-gpu--t4', 'mr,bn': 'ai4bharat/indictrans-v2-all-gpu--t4', 'mr,brx': 'ai4bharat/indictrans-v2-all-gpu--t4', 'mr,gu': 'ai4bharat/indictrans-v2-all-gpu--t4', 'mr,hi': 'ai4bharat/indictrans-v2-all-gpu--t4', 'mr,kn': 'ai4bharat/indictrans-v2-all-gpu--t4', 'mr,ml': 'ai4bharat/indictrans-v2-all-gpu--t4', 'mr,mni': 'ai4bharat/indictrans-v2-all-gpu--t4', 'mr,or': 'ai4bharat/indictrans-v2-all-gpu--t4', 'mr,pa': 'ai4bharat/indictrans-v2-all-gpu--t4', 'mr,ta': 'ai4bharat/indictrans-v2-all-gpu--t4', 'mr,te': 'ai4bharat/indictrans-v2-all-gpu--t4', 'or,en': 'ai4bharat/indictrans-v2-all-gpu--t4', 'or,as': 'ai4bharat/indictrans-v2-all-gpu--t4', 'or,bn': 'ai4bharat/indictrans-v2-all-gpu--t4', 'or,brx': 'ai4bharat/indictrans-v2-all-gpu--t4', 'or,gu': 'ai4bharat/indictrans-v2-all-gpu--t4', 'or,hi': 'ai4bharat/indictrans-v2-all-gpu--t4', 'or,kn': 'ai4bharat/indictrans-v2-all-gpu--t4', 'or,ml': 'ai4bharat/indictrans-v2-all-gpu--t4', 'or,mni': 'ai4bharat/indictrans-v2-all-gpu--t4', 'or,mr': 'ai4bharat/indictrans-v2-all-gpu--t4', 'or,pa': 'ai4bharat/indictrans-v2-all-gpu--t4', 'or,ta': 'ai4bharat/indictrans-v2-all-gpu--t4', 'or,te': 'ai4bharat/indictrans-v2-all-gpu--t4', 'pa,en': 'ai4bharat/indictrans-v2-all-gpu--t4', 'pa,as': 'ai4bharat/indictrans-v2-all-gpu--t4', 'pa,bn': 'ai4bharat/indictrans-v2-all-gpu--t4', 'pa,brx': 'ai4bharat/indictrans-v2-all-gpu--t4', 'pa,gu': 'ai4bharat/indictrans-v2-all-gpu--t4', 'pa,hi': 'ai4bharat/indictrans-v2-all-gpu--t4', 'pa,kn': 'ai4bharat/indictrans-v2-all-gpu--t4', 'pa,ml': 'ai4bharat/indictrans-v2-all-gpu--t4', 'pa,mni': 'ai4bharat/indictrans-v2-all-gpu--t4', 'pa,mr': 'ai4bharat/indictrans-v2-all-gpu--t4', 'pa,or': 'ai4bharat/indictrans-v2-all-gpu--t4', 'pa,ta': 'ai4bharat/indictrans-v2-all-gpu--t4', 'pa,te': 'ai4bharat/indictrans-v2-all-gpu--t4', 'sa,en': 'ai4bharat/indictrans-v2-all-gpu--t4', 'sa,as': 'ai4bharat/indictrans-v2-all-gpu--t4', 'sa,bn': 'ai4bharat/indictrans-v2-all-gpu--t4', 'sa,brx': 'ai4bharat/indictrans-v2-all-gpu--t4', 'sa,gu': 'ai4bharat/indictrans-v2-all-gpu--t4', 'sa,hi': 'ai4bharat/indictrans-v2-all-gpu--t4', 'sa,kn': 'ai4bharat/indictrans-v2-all-gpu--t4', 'sa,ml': 'ai4bharat/indictrans-v2-all-gpu--t4', 'sa,mni': 'ai4bharat/indictrans-v2-all-gpu--t4', 'sa,mr': 'ai4bharat/indictrans-v2-all-gpu--t4', 'sa,or': 'ai4bharat/indictrans-v2-all-gpu--t4', 'sa,pa': 'ai4bharat/indictrans-v2-all-gpu--t4', 'sa,ta': 'ai4bharat/indictrans-v2-all-gpu--t4', 'sa,te': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ta,en': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ta,as': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ta,bn': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ta,brx': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ta,gu': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ta,hi': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ta,kn': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ta,ml': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ta,mni': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ta,mr': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ta,or': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ta,pa': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ta,te': 'ai4bharat/indictrans-v2-all-gpu--t4', 'te,en': 'ai4bharat/indictrans-v2-all-gpu--t4', 'te,as': 'ai4bharat/indictrans-v2-all-gpu--t4', 'te,bn': 'ai4bharat/indictrans-v2-all-gpu--t4', 'te,brx': 'ai4bharat/indictrans-v2-all-gpu--t4', 'te,gu': 'ai4bharat/indictrans-v2-all-gpu--t4', 'te,hi': 'ai4bharat/indictrans-v2-all-gpu--t4', 'te,kn': 'ai4bharat/indictrans-v2-all-gpu--t4', 'te,ml': 'ai4bharat/indictrans-v2-all-gpu--t4', 'te,mni': 'ai4bharat/indictrans-v2-all-gpu--t4', 'te,mr': 'ai4bharat/indictrans-v2-all-gpu--t4', 'te,or': 'ai4bharat/indictrans-v2-all-gpu--t4', 'te,pa': 'ai4bharat/indictrans-v2-all-gpu--t4', 'te,ta': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ur,en': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ur,as': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ur,bn': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ur,brx': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ur,gu': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ur,hi': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ur,kn': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ur,ml': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ur,mni': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ur,mr': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ur,or': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ur,pa': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ur,ta': 'ai4bharat/indictrans-v2-all-gpu--t4', 'ur,te': 'ai4bharat/indictrans-v2-all-gpu--t4'}\n",
    "    comb = str(input_language) + \",\" + str(output_language)\n",
    "    nmt_serviceid_val = nmt_serviceid_dict[comb]\n",
    "\n",
    "    payload = json.dumps({\n",
    "      \"pipelineTasks\": [\n",
    "        {\n",
    "          \"taskType\": \"translation\",\n",
    "          \"config\": {\n",
    "            \"language\": {\n",
    "              \"sourceLanguage\": input_language,\n",
    "              \"targetLanguage\": output_language\n",
    "            },\n",
    "            \"serviceId\": nmt_serviceid_val\n",
    "          }\n",
    "        }\n",
    "      ],\n",
    "      \"inputData\": {\n",
    "        \"input\": [\n",
    "          {\n",
    "            \"source\": my_input\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    })\n",
    "    headers = {\n",
    "      'Accept': '*/*',\n",
    "      'User-Agent': 'Thunder Client (https://www.thunderclient.com)',\n",
    "      'Authorization': bhashini_api_key,\n",
    "      'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    json_data = json.loads(response.text)\n",
    "    output = json_data[\"pipelineResponse\"][0][\"output\"][0][\"target\"]\n",
    "    return output\n",
    "def tts(my_input, input_language):\n",
    "    url = \"https://dhruva-api.bhashini.gov.in/services/inference/pipeline\"\n",
    "    tts_serviceid_dict = {'en': 'ai4bharat/indic-tts-coqui-misc-gpu--t4', 'as': 'ai4bharat/indic-tts-coqui-indo_aryan-gpu--t4', 'brx': 'ai4bharat/indic-tts-coqui-misc-gpu--t4', 'gu': 'ai4bharat/indic-tts-coqui-indo_aryan-gpu--t4', 'hi': 'ai4bharat/indic-tts-coqui-indo_aryan-gpu--t4', 'kn': 'ai4bharat/indic-tts-coqui-dravidian-gpu--t4', 'ml': 'ai4bharat/indic-tts-coqui-dravidian-gpu--t4', 'mni': 'ai4bharat/indic-tts-coqui-misc-gpu--t4', 'mr': 'ai4bharat/indic-tts-coqui-indo_aryan-gpu--t4', 'or': 'ai4bharat/indic-tts-coqui-indo_aryan-gpu--t4', 'pa': 'ai4bharat/indic-tts-coqui-indo_aryan-gpu--t4', 'ta': 'ai4bharat/indic-tts-coqui-dravidian-gpu--t4', 'te': 'ai4bharat/indic-tts-coqui-dravidian-gpu--t4', 'bn': 'ai4bharat/indic-tts-coqui-indo_aryan-gpu--t4'}\n",
    "    tts_serviceid_val = tts_serviceid_dict[input_language]\n",
    "\n",
    "    payload = json.dumps({\n",
    "    \"pipelineTasks\": [\n",
    "        {\n",
    "        \"taskType\": \"tts\",\n",
    "        \"config\": {\n",
    "            \"language\": {\n",
    "            \"sourceLanguage\": input_language\n",
    "            },\n",
    "            \"serviceId\": tts_serviceid_val,\n",
    "            \"gender\": \"female\"\n",
    "        }\n",
    "        }\n",
    "    ],\n",
    "    \"inputData\": {\n",
    "        \"input\": [\n",
    "        {\n",
    "            \"source\": my_input\n",
    "        }\n",
    "        ]\n",
    "    }\n",
    "    })\n",
    "    headers = {\n",
    "    'Accept': '*/*',\n",
    "    'User-Agent': 'Thunder Client (https://www.thunderclient.com)',\n",
    "    'Authorization': bhashini_api_key,\n",
    "    'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    json_data = json.loads(response.text)\n",
    "    output = json_data[\"pipelineResponse\"][0][\"audio\"][0][\"audioContent\"]\n",
    "    # # Play the audio segment\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff66ddad-9b5e-4d40-ac08-7ce171e7b2fe",
   "metadata": {},
   "source": [
    "**Some Prompt Engineering to Help the Model Ouputs**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40542be-1468-4a0b-93b5-404c8fd7d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "promptY = \"SYSTEM PROMPT:You are a personal assistant whose name is Stella, who gives very accurate and long in detail answer , you will answer users queries in their respective language , for example if user asks question in hindi , you will try to answer in hindi aswell, you support languages - english , hindi , bengali , tamil , marathi , gujrati , punjabi , urdu , telugu , kannda , malyalam, So now answer the users Question- USER PROMPT : \"\n",
    "promptX = \"Assistant : \"\n",
    "imgPrompt = \"135mm IMAX UHD, 8k, f10, dslr, CANON/NIKON/SONY XXmm/XXXmm, ISO xxx, 1/250, 1 /500, 1/2000 etc, f1.4, f2.8, f4.0??\"\n",
    "bhashini_api_key = '-ZMTsWoHLAsGSKpgnvuwPF3LJUK71XPdYxnMPW6dC55JfDa_Sgy4vYi6JHi7ZnE0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae20ef4-f7e8-4a66-b187-8b552dc00d26",
   "metadata": {},
   "source": [
    "**Defining The Base Level Pipelines for Text2Text Text2Image and Text2Speech**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925f1e9b-c729-4da8-a923-5bf397c57117",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalAI:\n",
    "    def __init__(self):\n",
    "            # FireworksAI API credentials\n",
    "\n",
    "            #old key -- 3J2VhOCg9nJF30zpLUJvlALsMAM0zG6b9KjJf1PhX7mx7GIn\n",
    "            \n",
    "            self.fireworks_api_key = \"4rFyL3QY1ro1TyPjAP5XEYA7vvxQCwAW29ZRmDkWql9gOdhq\"\n",
    "            self.fireworks_url = \"https://api.fireworks.ai/inference/v1/chat/completions\"\n",
    "            self.fireworks_headers = {\n",
    "                \"Accept\": \"application/json\",\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Authorization\": f\"Bearer {self.fireworks_api_key}\"\n",
    "            }\n",
    "\n",
    "            # RunPod API credentials\n",
    "            self.runpod_api_key = \"PX3E31M7X73TBZQW8FL8JZ8I5GD52ALJGMTIGVD1\"\n",
    "            self.runpod_url = \"https://api.runpod.ai/v2/sdxl/runsync\"\n",
    "            self.runpod_headers = {\n",
    "                \"accept\": \"application/json\",\n",
    "                \"content-type\": \"application/json\", \n",
    "                \"authorization\": self.runpod_api_key\n",
    "            }\n",
    "\n",
    "    \n",
    "    def t2t(self, input_language, user_message): #text2text\n",
    "            if input_language==\"en\":\n",
    "                fireworks_headers = {\n",
    "                \"Accept\": \"application/json\",\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Authorization\": f\"Bearer {self.fireworks_api_key}\"\n",
    "                }\n",
    "                payload = {\n",
    "                    \"model\": \"accounts/fireworks/models/mixtral-8x7b-instruct\",\n",
    "                    \"max_tokens\": 4096,\n",
    "                    \"top_p\": 1,\n",
    "                    \"top_k\": 40,\n",
    "                    \"presence_penalty\": 0,\n",
    "                    \"frequency_penalty\": 0,\n",
    "                    \"temperature\": 0.6,\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": promptY+user_message+promptX\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "                response = requests.request(\"POST\",\"https://api.fireworks.ai/inference/v1/chat/completions\", headers=fireworks_headers, data=json.dumps(payload))\n",
    "                llm_response = response.json()['choices'][0]['message']['content'].replace('\\\\n', '')\n",
    "                return llm_response\n",
    "            else:\n",
    "                translated_text = nmt(user_message, input_language, \"en\")\n",
    "                fireworks_headers = {\n",
    "                \"Accept\": \"application/json\",\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Authorization\": f\"Bearer {self.fireworks_api_key}\"\n",
    "                }\n",
    "                payload = {\n",
    "                    \"model\": \"accounts/fireworks/models/mixtral-8x7b-instruct\",\n",
    "                    \"max_tokens\": 4096,\n",
    "                    \"top_p\": 1,\n",
    "                    \"top_k\": 40,\n",
    "                    \"presence_penalty\": 0,\n",
    "                    \"frequency_penalty\": 0,\n",
    "                    \"temperature\": 0.6,\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": promptY+user_message+promptX\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "                response = requests.request(\"POST\",\"https://api.fireworks.ai/inference/v1/chat/completions\", headers=fireworks_headers, data=json.dumps(payload))\n",
    "                llm_response = response.json()['choices'][0]['message']['content'].replace('\\\\n', '')\n",
    "                translated_text = nmt(llm_response, \"en\", input_language)\n",
    "                return translated_text\n",
    "\n",
    "               \n",
    "                \n",
    "            \n",
    "    def t2i(self,input_language,user_message):  #text2image\n",
    "            if input_language==\"en\":\n",
    "                payload = {\n",
    "                    \"input\": {\n",
    "                    \"prompt\": user_message+imgPrompt,\n",
    "                    \"num_inference_steps\": 40,\n",
    "                    \"refiner_inference_steps\": 30,\n",
    "                    \"width\": 1024,\n",
    "                    \"height\": 1024,\n",
    "                    \"guidance_scale\": 7,\n",
    "                    \"strength\": 0.5,\n",
    "                    \"seed\": None,\n",
    "                    \"num_images\": 1,\n",
    "                    \"negative_prompt\": \"bad anatomy, bad hands, three hands, three legs, bad arms, missing legs, missing arms, poorly drawn face, bad face, fused face, cloned face, worst face, three crus, extra crus, fused crus, worst feet, three feet, fused feet, fused thigh, three thigh, fused thigh, extra thigh, worst thigh, missing fingers, extra fingers, ugly fingers, long fingers, horn, extra eyes, huge eyes, 2girl, amputation, disconnected limbs, cartoon, cg, 3d, unreal, animate\"\n",
    "                    }\n",
    "                }\n",
    "                response = requests.post(self.runpod_url, json=payload, headers=self.runpod_headers)\n",
    "                data = response.json()\n",
    "                image_url = data[\"output\"][\"image_url\"]\n",
    "                return image_url\n",
    "            else:\n",
    "                translated_text = nmt(user_message, input_language, \"en\")\n",
    "                payload = {\n",
    "                    \"input\": {\n",
    "                    \"prompt\": translated_text+imgPrompt,\n",
    "                    \"num_inference_steps\": 40,\n",
    "                    \"refiner_inference_steps\": 30,\n",
    "                    \"width\": 1024,\n",
    "                    \"height\": 1024,\n",
    "                    \"guidance_scale\": 7,\n",
    "                    \"strength\": 0.5,\n",
    "                    \"seed\": None,\n",
    "                    \"num_images\": 1,\n",
    "                    \"negative_prompt\": \"bad anatomy, bad hands, three hands, three legs, bad arms, missing legs, missing arms, poorly drawn face, bad face, fused face, cloned face, worst face, three crus, extra crus, fused crus, worst feet, three feet, fused feet, fused thigh, three thigh, fused thigh, extra thigh, worst thigh, missing fingers, extra fingers, ugly fingers, long fingers, horn, extra eyes, huge eyes, 2girl, amputation, disconnected limbs, cartoon, cg, 3d, unreal, animate\"\n",
    "                    }\n",
    "                }\n",
    "                response = requests.post(self.runpod_url, json=payload, headers=self.runpod_headers)\n",
    "                data = response.json()\n",
    "                image_url = data[\"output\"][\"image_url\"]\n",
    "                return image_url\n",
    "    def t2s(self, input_language, user_message):  #text2speech\n",
    "            if input_language==\"en\":\n",
    "                fireworks_headers = {\n",
    "                \"Accept\": \"application/json\",\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Authorization\": f\"Bearer {self.fireworks_api_key}\"\n",
    "                }\n",
    "                payload = {\n",
    "                    \"model\": \"accounts/fireworks/models/mixtral-8x7b-instruct\",\n",
    "                    \"max_tokens\": 4096,\n",
    "                    \"top_p\": 1,\n",
    "                    \"top_k\": 40,\n",
    "                    \"presence_penalty\": 0,\n",
    "                    \"frequency_penalty\": 0,\n",
    "                    \"temperature\": 0.6,\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": promptY+user_message+promptX\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "                response = requests.request(\"POST\",\"https://api.fireworks.ai/inference/v1/chat/completions\", headers=fireworks_headers, data=json.dumps(payload))\n",
    "                llm_response = response.json()['choices'][0]['message']['content'].replace('\\\\n', '')\n",
    "                tts_response = tts(llm_response, \"en\")\n",
    "                return tts_response\n",
    "            else:\n",
    "                translated_text = nmt(user_message, input_language, \"en\")\n",
    "                fireworks_headers = {\n",
    "                \"Accept\": \"application/json\",\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Authorization\": f\"Bearer {self.fireworks_api_key}\"\n",
    "                }\n",
    "                payload = {\n",
    "                    \"model\": \"accounts/fireworks/models/mixtral-8x7b-instruct\",\n",
    "                    \"max_tokens\": 4096,\n",
    "                    \"top_p\": 1,\n",
    "                    \"top_k\": 40,\n",
    "                    \"presence_penalty\": 0,\n",
    "                    \"frequency_penalty\": 0,\n",
    "                    \"temperature\": 0.6,\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": promptY+user_message+promptX\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "                response = requests.request(\"POST\",\"https://api.fireworks.ai/inference/v1/chat/completions\", headers=fireworks_headers, data=json.dumps(payload))\n",
    "                llm_response = response.json()['choices'][0]['message']['content'].replace('\\\\n', '')\n",
    "                translated_text = nmt(llm_response, \"en\", input_language)\n",
    "                tts_response = tts(llm_response, input_language)\n",
    "                return tts_response   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5c3b00-aa79-4c7f-ad95-001765a7d5ec",
   "metadata": {},
   "source": [
    "**Demo for the above Pipelines**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2ff651-9d2a-4319-ad78-a06f2ece6973",
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_ai = MultimodalAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d229785-074f-4157-8d01-7ac20b274b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_t2t():\n",
    "    # Take input text from user\n",
    "    input_text = input(\"User Prompt: \")\n",
    "    # Input language\n",
    "    input_language = input(\"Enter input language code (e.g., en, hi, bn): \")\n",
    "    # Translate text\n",
    "    answer = multimodal_ai.t2t(input_language,input_text)\n",
    "    print(\"Response:\", answer)\n",
    "print(\"Text 2 Text Demo:\")\n",
    "demonstrate_t2t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c2b75c-964b-4675-a564-a13112b01f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_t2s():\n",
    "    # Take input text from user\n",
    "    input_text = input(\"User Prompt: \")\n",
    "    # Input language\n",
    "    input_language = input(\"Enter input language code (e.g., en, hi, bn): \")\n",
    "    # Generate Base64 encoded speech\n",
    "    response = multimodal_ai.t2s(input_language,input_text)\n",
    "    # Convert Base64 to WAV\n",
    "    response_speech = base64.b64decode(response)\n",
    "    with open(\"output_audio.wav\", \"wb\") as f:\n",
    "        f.write(response_speech)\n",
    "    \n",
    "    # Display the audio\n",
    "    ipd.display(ipd.Audio(\"output_audio.wav\"))\n",
    "print(\"\\nText 2 Speech Pipeline Demo:\")\n",
    "demonstrate_t2s()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eccffb2-9cfa-414c-bc03-28b76949cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_t2t():\n",
    "    # Take input text from user\n",
    "    input_text = input(\"Image to Generate: \")\n",
    "    # Input language\n",
    "    input_language = input(\"Enter input language code (e.g., en, hi, bn): \")\n",
    "    # Translate text\n",
    "    answer = multimodal_ai.t2i(input_language,input_text)\n",
    "    print(\"Response:\", answer)\n",
    "print(\"Text 2 Image Demo:\")\n",
    "demonstrate_t2t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae1037e-f8a8-4b5d-b442-da284be9cdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install fasttext\n",
    "!pip install torch\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc4d330-4997-4492-92d1-0d6d4df6aa78",
   "metadata": {},
   "source": [
    "**Now lets bring in Seamless Language Detection into this (Check LID section in our Github Repo For More Detailed Look)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04da5c6-f524-48e7-8251-bafda031eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/akash-mondal/IndicLID.git\n",
    "%cd \"IndicLID/Inference/models\"\n",
    "!wget https://github.com/AI4Bharat/IndicLID/releases/download/v1.0/indiclid-bert.zip\n",
    "!wget https://github.com/AI4Bharat/IndicLID/releases/download/v1.0/indiclid-ftn.zip\n",
    "!wget https://github.com/AI4Bharat/IndicLID/releases/download/v1.0/indiclid-ftr.zip\n",
    "!unzip indiclid-bert.zip\n",
    "!unzip indiclid-ftn.zip\n",
    "!unzip indiclid-ftr.zip\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8071a5b2-d4a6-4ee6-b3e2-34939683f144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai4bharat.IndicLID import IndicLID\n",
    "\n",
    "IndicLID_model = IndicLID(input_threshold = 0.5, roman_lid_threshold = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feba47e-a48c-4f55-ad39-3b9f051dd51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_iso(data_list):\n",
    "    def script_to_iso(script_code):\n",
    "        script_mapping = {\n",
    "            'Beng': 'bn',\n",
    "            'Latn': 'en',\n",
    "            'Deva': 'hi',\n",
    "            'Gujr': 'gu',\n",
    "            'Knda': 'kn',\n",
    "            'Arab': 'ur',\n",
    "            'Mlym': 'ml',\n",
    "            'Orya': 'or',\n",
    "            'Guru': 'pa',\n",
    "            'Tamil': 'ta',\n",
    "            'Telu': 'te',\n",
    "            'Olch': 'sat',\n",
    "            'Meti': 'mni'\n",
    "        }\n",
    "        script_parts = script_code.split('_')\n",
    "        if len(script_parts) != 2:\n",
    "            return None  # Invalid input format\n",
    "        script = script_parts[1]\n",
    "        iso_script = script_mapping.get(script, None)\n",
    "        if iso_script:\n",
    "            return iso_script\n",
    "        else:\n",
    "            return None  # Invalid script code\n",
    "\n",
    "    extracted_iso_codes = []\n",
    "    for item in data_list:\n",
    "        language = item[1]\n",
    "        iso_code = script_to_iso(language)\n",
    "        if iso_code:\n",
    "            extracted_iso_codes.append(iso_code)\n",
    "    return ' '.join(extracted_iso_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d296bb6-6aa6-4ddc-ac21-3e5ea795a294",
   "metadata": {},
   "source": [
    "**Now Lets Add Language Identification to the previouse pipelines to make them Seamless!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c726f7-e947-44bf-bb14-16e82de77d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeamlessAI:\n",
    "    def __init__(self):\n",
    "            # FireworksAI API credentials\n",
    "\n",
    "            #old key -- 3J2VhOCg9nJF30zpLUJvlALsMAM0zG6b9KjJf1PhX7mx7GIn\n",
    "            \n",
    "            self.fireworks_api_key = \"4rFyL3QY1ro1TyPjAP5XEYA7vvxQCwAW29ZRmDkWql9gOdhq\"\n",
    "            self.fireworks_url = \"https://api.fireworks.ai/inference/v1/chat/completions\"\n",
    "            self.fireworks_headers = {\n",
    "                \"Accept\": \"application/json\",\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Authorization\": f\"Bearer {self.fireworks_api_key}\"\n",
    "            }\n",
    "\n",
    "            # RunPod API credentials\n",
    "            self.runpod_api_key = \"PX3E31M7X73TBZQW8FL8JZ8I5GD52ALJGMTIGVD1\"\n",
    "            self.runpod_url = \"https://api.runpod.ai/v2/sdxl/runsync\"\n",
    "            self.runpod_headers = {\n",
    "                \"accept\": \"application/json\",\n",
    "                \"content-type\": \"application/json\", \n",
    "                \"authorization\": self.runpod_api_key\n",
    "            }\n",
    "\n",
    "    \n",
    "    def t2t(self, user_message): #text2text\n",
    "            # Split the user_message into words\n",
    "            words = user_message.split()\n",
    "            # Select the first 100 words or less\n",
    "            sample = ' '.join(words[:100])\n",
    "            textsamples = []\n",
    "            textsamples.append(sample)\n",
    "            batch_size = 1\n",
    "            outputs = IndicLID_model.batch_predict(textsamples, batch_size)\n",
    "            input_language = extract_iso(outputs)\n",
    "            if input_language==\"en\":\n",
    "                fireworks_headers = {\n",
    "                \"Accept\": \"application/json\",\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Authorization\": f\"Bearer {self.fireworks_api_key}\"\n",
    "                }\n",
    "                payload = {\n",
    "                    \"model\": \"accounts/fireworks/models/mixtral-8x7b-instruct\",\n",
    "                    \"max_tokens\": 4096,\n",
    "                    \"top_p\": 1,\n",
    "                    \"top_k\": 40,\n",
    "                    \"presence_penalty\": 0,\n",
    "                    \"frequency_penalty\": 0,\n",
    "                    \"temperature\": 0.6,\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": promptY+user_message+promptX\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "                response = requests.request(\"POST\",\"https://api.fireworks.ai/inference/v1/chat/completions\", headers=fireworks_headers, data=json.dumps(payload))\n",
    "                llm_response = response.json()['choices'][0]['message']['content'].replace('\\\\n', '')\n",
    "                return llm_response\n",
    "            else:\n",
    "                translated_text = nmt(user_message, input_language, \"en\")\n",
    "                fireworks_headers = {\n",
    "                \"Accept\": \"application/json\",\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Authorization\": f\"Bearer {self.fireworks_api_key}\"\n",
    "                }\n",
    "                payload = {\n",
    "                    \"model\": \"accounts/fireworks/models/mixtral-8x7b-instruct\",\n",
    "                    \"max_tokens\": 4096,\n",
    "                    \"top_p\": 1,\n",
    "                    \"top_k\": 40,\n",
    "                    \"presence_penalty\": 0,\n",
    "                    \"frequency_penalty\": 0,\n",
    "                    \"temperature\": 0.6,\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": promptY+user_message+promptX\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "                response = requests.request(\"POST\",\"https://api.fireworks.ai/inference/v1/chat/completions\", headers=fireworks_headers, data=json.dumps(payload))\n",
    "                llm_response = response.json()['choices'][0]['message']['content'].replace('\\\\n', '')\n",
    "                translated_text = nmt(llm_response, \"en\", input_language)\n",
    "                return translated_text\n",
    "\n",
    "               \n",
    "                \n",
    "               \n",
    "                \n",
    "            \n",
    "    def t2i(self,user_message):  #text2image\n",
    "            # Split the user_message into words\n",
    "            words = user_message.split()\n",
    "            # Select the first 100 words or less\n",
    "            sample = ' '.join(words[:100])\n",
    "            textsamples = []\n",
    "            textsamples.append(sample)\n",
    "            batch_size = 1\n",
    "            outputs = IndicLID_model.batch_predict(textsamples, batch_size)\n",
    "            input_language = extract_iso(outputs)\n",
    "            if input_language==\"en\":\n",
    "                payload = {\n",
    "                    \"input\": {\n",
    "                    \"prompt\": user_message+imgPrompt,\n",
    "                    \"num_inference_steps\": 40,\n",
    "                    \"refiner_inference_steps\": 30,\n",
    "                    \"width\": 1024,\n",
    "                    \"height\": 1024,\n",
    "                    \"guidance_scale\": 7,\n",
    "                    \"strength\": 0.5,\n",
    "                    \"seed\": None,\n",
    "                    \"num_images\": 1,\n",
    "                    \"negative_prompt\": \"bad anatomy, bad hands, three hands, three legs, bad arms, missing legs, missing arms, poorly drawn face, bad face, fused face, cloned face, worst face, three crus, extra crus, fused crus, worst feet, three feet, fused feet, fused thigh, three thigh, fused thigh, extra thigh, worst thigh, missing fingers, extra fingers, ugly fingers, long fingers, horn, extra eyes, huge eyes, 2girl, amputation, disconnected limbs, cartoon, cg, 3d, unreal, animate\"\n",
    "                    }\n",
    "                }\n",
    "                response = requests.post(self.runpod_url, json=payload, headers=self.runpod_headers)\n",
    "                data = response.json()\n",
    "                image_url = data[\"output\"][\"image_url\"]\n",
    "                return image_url\n",
    "            else:\n",
    "                translated_text = nmt(user_message, input_language, \"en\")\n",
    "                payload = {\n",
    "                    \"input\": {\n",
    "                    \"prompt\": translated_text+imgPrompt,\n",
    "                    \"num_inference_steps\": 40,\n",
    "                    \"refiner_inference_steps\": 30,\n",
    "                    \"width\": 1024,\n",
    "                    \"height\": 1024,\n",
    "                    \"guidance_scale\": 7,\n",
    "                    \"strength\": 0.5,\n",
    "                    \"seed\": None,\n",
    "                    \"num_images\": 1,\n",
    "                    \"negative_prompt\": \"bad anatomy, bad hands, three hands, three legs, bad arms, missing legs, missing arms, poorly drawn face, bad face, fused face, cloned face, worst face, three crus, extra crus, fused crus, worst feet, three feet, fused feet, fused thigh, three thigh, fused thigh, extra thigh, worst thigh, missing fingers, extra fingers, ugly fingers, long fingers, horn, extra eyes, huge eyes, 2girl, amputation, disconnected limbs, cartoon, cg, 3d, unreal, animate\"\n",
    "                    }\n",
    "                }\n",
    "                response = requests.post(self.runpod_url, json=payload, headers=self.runpod_headers)\n",
    "                data = response.json()\n",
    "                image_url = data[\"output\"][\"image_url\"]\n",
    "                return image_url\n",
    "    def t2s(self, user_message):  #text2speech\n",
    "            # Split the user_message into words\n",
    "            words = user_message.split()\n",
    "            # Select the first 100 words or less\n",
    "            sample = ' '.join(words[:100])\n",
    "            textsamples = []\n",
    "            textsamples.append(sample)\n",
    "            batch_size = 1\n",
    "            outputs = IndicLID_model.batch_predict(textsamples, batch_size)\n",
    "            input_language = extract_iso(outputs)\n",
    "            if input_language==\"en\":\n",
    "                fireworks_headers = {\n",
    "                \"Accept\": \"application/json\",\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Authorization\": f\"Bearer {self.fireworks_api_key}\"\n",
    "                }\n",
    "                payload = {\n",
    "                    \"model\": \"accounts/fireworks/models/mixtral-8x7b-instruct\",\n",
    "                    \"max_tokens\": 4096,\n",
    "                    \"top_p\": 1,\n",
    "                    \"top_k\": 40,\n",
    "                    \"presence_penalty\": 0,\n",
    "                    \"frequency_penalty\": 0,\n",
    "                    \"temperature\": 0.6,\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": promptY+user_message+promptX\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "                response = requests.request(\"POST\",\"https://api.fireworks.ai/inference/v1/chat/completions\", headers=fireworks_headers, data=json.dumps(payload))\n",
    "                llm_response = response.json()['choices'][0]['message']['content'].replace('\\\\n', '')\n",
    "                tts_response = tts(llm_response, \"en\")\n",
    "                return tts_response\n",
    "            else:\n",
    "                translated_text = nmt(user_message, input_language, \"en\")\n",
    "                fireworks_headers = {\n",
    "                \"Accept\": \"application/json\",\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Authorization\": f\"Bearer {self.fireworks_api_key}\"\n",
    "                }\n",
    "                payload = {\n",
    "                    \"model\": \"accounts/fireworks/models/mixtral-8x7b-instruct\",\n",
    "                    \"max_tokens\": 4096,\n",
    "                    \"top_p\": 1,\n",
    "                    \"top_k\": 40,\n",
    "                    \"presence_penalty\": 0,\n",
    "                    \"frequency_penalty\": 0,\n",
    "                    \"temperature\": 0.6,\n",
    "                    \"messages\": [\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": promptY+user_message+promptX\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "                response = requests.request(\"POST\",\"https://api.fireworks.ai/inference/v1/chat/completions\", headers=fireworks_headers, data=json.dumps(payload))\n",
    "                llm_response = response.json()['choices'][0]['message']['content'].replace('\\\\n', '')\n",
    "                translated_text = nmt(llm_response, \"en\", input_language)\n",
    "                tts_response = tts(llm_response, input_language)\n",
    "                return tts_response    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3c9b58-7f92-4dd5-ac89-85ccf01850e9",
   "metadata": {},
   "source": [
    "**Now Lets use these new Pipelines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b70057e-3b28-48cd-976d-697757f34547",
   "metadata": {},
   "outputs": [],
   "source": [
    "seamless_ai = SeamlessAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41f3d33-8c42-48b1-bf21-ad034a7ce501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_t2t():\n",
    "    # Take input text from user\n",
    "    input_text = input(\"User Prompt: \")\n",
    "    answer = seamless_ai.t2t(input_text)\n",
    "    print(\"Response:\", answer)\n",
    "print(\"Seamless Text 2 Text Demo:\")\n",
    "demonstrate_t2t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b34f2dc-7742-4031-870a-755b830cd3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_t2s():\n",
    "    # Take input text from user\n",
    "    input_text = input(\"User Prompt: \")\n",
    "    # Generate Base64 encoded speech\n",
    "    response = seamless_ai.t2s(input_text)\n",
    "    # Convert Base64 to WAV\n",
    "    response_speech = base64.b64decode(response)\n",
    "    with open(\"output_audio.wav\", \"wb\") as f:\n",
    "        f.write(response_speech)\n",
    "    \n",
    "    # Display the audio\n",
    "    ipd.display(ipd.Audio(\"output_audio.wav\"))\n",
    "print(\"\\nText 2 Speech Pipeline Demo:\")\n",
    "demonstrate_t2s()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263e5a7f-46e0-4150-b588-6bcb86e4ea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_t2t():\n",
    "    # Take input text from user\n",
    "    input_text = input(\"Image to Generate: \")\n",
    "    answer = seamless_ai.t2i(input_text)\n",
    "    print(\"Response:\", answer)\n",
    "print(\"Text 2 Image Demo:\")\n",
    "demonstrate_t2t()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289405ea-4533-4d76-84ad-8a5311b69c04",
   "metadata": {},
   "source": [
    "# Just Like this you can make your own pipelines to make a multimodal multilingual personal assistant , for speech input use a SpeechLID (Code available in our Github https://github.com/akash-mondal/Seamless-AI) and for image input add in a Visual Language Model like CogVLM or LLaVA (Demo available in our Github)(Seamless Glasses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
